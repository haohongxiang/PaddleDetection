{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "from ppdet.core.workspace import load_config, create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############patch here!!!\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config('./configs/cascade_rcnn/vit_base_16_hrfpn.yml')\n",
    "model = create(cfg.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')['model']\n",
    "\n",
    "state = {k.strip('encoder.'): v for k, v in state.items() if 'encoder' in k}\n",
    "\n",
    "_state = {}\n",
    "for n, p in model.backbone.state_dict().items():\n",
    "    if n in state:\n",
    "        if len(p.shape) == 2:\n",
    "            _state[n] = state[n].data.numpy().T\n",
    "        else:\n",
    "            _state[n] = state[n].data.numpy()\n",
    "\n",
    "            \n",
    "model.backbone.set_state_dict(_state)\n",
    "\n",
    "paddle.save(_state, '../params/pretrain_mae_vit_base_mask_0.75_400e.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token\n",
      "encoder.patch_embed.proj.weight\n",
      "encoder.patch_embed.proj.bias\n",
      "encoder.blocks.0.norm1.weight\n",
      "encoder.blocks.0.norm1.bias\n",
      "encoder.blocks.0.attn.q_bias\n",
      "encoder.blocks.0.attn.v_bias\n",
      "encoder.blocks.0.attn.qkv.weight\n",
      "encoder.blocks.0.attn.proj.weight\n",
      "encoder.blocks.0.attn.proj.bias\n",
      "encoder.blocks.0.norm2.weight\n",
      "encoder.blocks.0.norm2.bias\n",
      "encoder.blocks.0.mlp.fc1.weight\n",
      "encoder.blocks.0.mlp.fc1.bias\n",
      "encoder.blocks.0.mlp.fc2.weight\n",
      "encoder.blocks.0.mlp.fc2.bias\n",
      "encoder.blocks.1.norm1.weight\n",
      "encoder.blocks.1.norm1.bias\n",
      "encoder.blocks.1.attn.q_bias\n",
      "encoder.blocks.1.attn.v_bias\n",
      "encoder.blocks.1.attn.qkv.weight\n",
      "encoder.blocks.1.attn.proj.weight\n",
      "encoder.blocks.1.attn.proj.bias\n",
      "encoder.blocks.1.norm2.weight\n",
      "encoder.blocks.1.norm2.bias\n",
      "encoder.blocks.1.mlp.fc1.weight\n",
      "encoder.blocks.1.mlp.fc1.bias\n",
      "encoder.blocks.1.mlp.fc2.weight\n",
      "encoder.blocks.1.mlp.fc2.bias\n",
      "encoder.blocks.2.norm1.weight\n",
      "encoder.blocks.2.norm1.bias\n",
      "encoder.blocks.2.attn.q_bias\n",
      "encoder.blocks.2.attn.v_bias\n",
      "encoder.blocks.2.attn.qkv.weight\n",
      "encoder.blocks.2.attn.proj.weight\n",
      "encoder.blocks.2.attn.proj.bias\n",
      "encoder.blocks.2.norm2.weight\n",
      "encoder.blocks.2.norm2.bias\n",
      "encoder.blocks.2.mlp.fc1.weight\n",
      "encoder.blocks.2.mlp.fc1.bias\n",
      "encoder.blocks.2.mlp.fc2.weight\n",
      "encoder.blocks.2.mlp.fc2.bias\n",
      "encoder.blocks.3.norm1.weight\n",
      "encoder.blocks.3.norm1.bias\n",
      "encoder.blocks.3.attn.q_bias\n",
      "encoder.blocks.3.attn.v_bias\n",
      "encoder.blocks.3.attn.qkv.weight\n",
      "encoder.blocks.3.attn.proj.weight\n",
      "encoder.blocks.3.attn.proj.bias\n",
      "encoder.blocks.3.norm2.weight\n",
      "encoder.blocks.3.norm2.bias\n",
      "encoder.blocks.3.mlp.fc1.weight\n",
      "encoder.blocks.3.mlp.fc1.bias\n",
      "encoder.blocks.3.mlp.fc2.weight\n",
      "encoder.blocks.3.mlp.fc2.bias\n",
      "encoder.blocks.4.norm1.weight\n",
      "encoder.blocks.4.norm1.bias\n",
      "encoder.blocks.4.attn.q_bias\n",
      "encoder.blocks.4.attn.v_bias\n",
      "encoder.blocks.4.attn.qkv.weight\n",
      "encoder.blocks.4.attn.proj.weight\n",
      "encoder.blocks.4.attn.proj.bias\n",
      "encoder.blocks.4.norm2.weight\n",
      "encoder.blocks.4.norm2.bias\n",
      "encoder.blocks.4.mlp.fc1.weight\n",
      "encoder.blocks.4.mlp.fc1.bias\n",
      "encoder.blocks.4.mlp.fc2.weight\n",
      "encoder.blocks.4.mlp.fc2.bias\n",
      "encoder.blocks.5.norm1.weight\n",
      "encoder.blocks.5.norm1.bias\n",
      "encoder.blocks.5.attn.q_bias\n",
      "encoder.blocks.5.attn.v_bias\n",
      "encoder.blocks.5.attn.qkv.weight\n",
      "encoder.blocks.5.attn.proj.weight\n",
      "encoder.blocks.5.attn.proj.bias\n",
      "encoder.blocks.5.norm2.weight\n",
      "encoder.blocks.5.norm2.bias\n",
      "encoder.blocks.5.mlp.fc1.weight\n",
      "encoder.blocks.5.mlp.fc1.bias\n",
      "encoder.blocks.5.mlp.fc2.weight\n",
      "encoder.blocks.5.mlp.fc2.bias\n",
      "encoder.blocks.6.norm1.weight\n",
      "encoder.blocks.6.norm1.bias\n",
      "encoder.blocks.6.attn.q_bias\n",
      "encoder.blocks.6.attn.v_bias\n",
      "encoder.blocks.6.attn.qkv.weight\n",
      "encoder.blocks.6.attn.proj.weight\n",
      "encoder.blocks.6.attn.proj.bias\n",
      "encoder.blocks.6.norm2.weight\n",
      "encoder.blocks.6.norm2.bias\n",
      "encoder.blocks.6.mlp.fc1.weight\n",
      "encoder.blocks.6.mlp.fc1.bias\n",
      "encoder.blocks.6.mlp.fc2.weight\n",
      "encoder.blocks.6.mlp.fc2.bias\n",
      "encoder.blocks.7.norm1.weight\n",
      "encoder.blocks.7.norm1.bias\n",
      "encoder.blocks.7.attn.q_bias\n",
      "encoder.blocks.7.attn.v_bias\n",
      "encoder.blocks.7.attn.qkv.weight\n",
      "encoder.blocks.7.attn.proj.weight\n",
      "encoder.blocks.7.attn.proj.bias\n",
      "encoder.blocks.7.norm2.weight\n",
      "encoder.blocks.7.norm2.bias\n",
      "encoder.blocks.7.mlp.fc1.weight\n",
      "encoder.blocks.7.mlp.fc1.bias\n",
      "encoder.blocks.7.mlp.fc2.weight\n",
      "encoder.blocks.7.mlp.fc2.bias\n",
      "encoder.blocks.8.norm1.weight\n",
      "encoder.blocks.8.norm1.bias\n",
      "encoder.blocks.8.attn.q_bias\n",
      "encoder.blocks.8.attn.v_bias\n",
      "encoder.blocks.8.attn.qkv.weight\n",
      "encoder.blocks.8.attn.proj.weight\n",
      "encoder.blocks.8.attn.proj.bias\n",
      "encoder.blocks.8.norm2.weight\n",
      "encoder.blocks.8.norm2.bias\n",
      "encoder.blocks.8.mlp.fc1.weight\n",
      "encoder.blocks.8.mlp.fc1.bias\n",
      "encoder.blocks.8.mlp.fc2.weight\n",
      "encoder.blocks.8.mlp.fc2.bias\n",
      "encoder.blocks.9.norm1.weight\n",
      "encoder.blocks.9.norm1.bias\n",
      "encoder.blocks.9.attn.q_bias\n",
      "encoder.blocks.9.attn.v_bias\n",
      "encoder.blocks.9.attn.qkv.weight\n",
      "encoder.blocks.9.attn.proj.weight\n",
      "encoder.blocks.9.attn.proj.bias\n",
      "encoder.blocks.9.norm2.weight\n",
      "encoder.blocks.9.norm2.bias\n",
      "encoder.blocks.9.mlp.fc1.weight\n",
      "encoder.blocks.9.mlp.fc1.bias\n",
      "encoder.blocks.9.mlp.fc2.weight\n",
      "encoder.blocks.9.mlp.fc2.bias\n",
      "encoder.blocks.10.norm1.weight\n",
      "encoder.blocks.10.norm1.bias\n",
      "encoder.blocks.10.attn.q_bias\n",
      "encoder.blocks.10.attn.v_bias\n",
      "encoder.blocks.10.attn.qkv.weight\n",
      "encoder.blocks.10.attn.proj.weight\n",
      "encoder.blocks.10.attn.proj.bias\n",
      "encoder.blocks.10.norm2.weight\n",
      "encoder.blocks.10.norm2.bias\n",
      "encoder.blocks.10.mlp.fc1.weight\n",
      "encoder.blocks.10.mlp.fc1.bias\n",
      "encoder.blocks.10.mlp.fc2.weight\n",
      "encoder.blocks.10.mlp.fc2.bias\n",
      "encoder.blocks.11.norm1.weight\n",
      "encoder.blocks.11.norm1.bias\n",
      "encoder.blocks.11.attn.q_bias\n",
      "encoder.blocks.11.attn.v_bias\n",
      "encoder.blocks.11.attn.qkv.weight\n",
      "encoder.blocks.11.attn.proj.weight\n",
      "encoder.blocks.11.attn.proj.bias\n",
      "encoder.blocks.11.norm2.weight\n",
      "encoder.blocks.11.norm2.bias\n",
      "encoder.blocks.11.mlp.fc1.weight\n",
      "encoder.blocks.11.mlp.fc1.bias\n",
      "encoder.blocks.11.mlp.fc2.weight\n",
      "encoder.blocks.11.mlp.fc2.bias\n",
      "encoder.norm.weight\n",
      "encoder.norm.bias\n",
      "decoder.blocks.0.norm1.weight\n",
      "decoder.blocks.0.norm1.bias\n",
      "decoder.blocks.0.attn.q_bias\n",
      "decoder.blocks.0.attn.v_bias\n",
      "decoder.blocks.0.attn.qkv.weight\n",
      "decoder.blocks.0.attn.proj.weight\n",
      "decoder.blocks.0.attn.proj.bias\n",
      "decoder.blocks.0.norm2.weight\n",
      "decoder.blocks.0.norm2.bias\n",
      "decoder.blocks.0.mlp.fc1.weight\n",
      "decoder.blocks.0.mlp.fc1.bias\n",
      "decoder.blocks.0.mlp.fc2.weight\n",
      "decoder.blocks.0.mlp.fc2.bias\n",
      "decoder.blocks.1.norm1.weight\n",
      "decoder.blocks.1.norm1.bias\n",
      "decoder.blocks.1.attn.q_bias\n",
      "decoder.blocks.1.attn.v_bias\n",
      "decoder.blocks.1.attn.qkv.weight\n",
      "decoder.blocks.1.attn.proj.weight\n",
      "decoder.blocks.1.attn.proj.bias\n",
      "decoder.blocks.1.norm2.weight\n",
      "decoder.blocks.1.norm2.bias\n",
      "decoder.blocks.1.mlp.fc1.weight\n",
      "decoder.blocks.1.mlp.fc1.bias\n",
      "decoder.blocks.1.mlp.fc2.weight\n",
      "decoder.blocks.1.mlp.fc2.bias\n",
      "decoder.blocks.2.norm1.weight\n",
      "decoder.blocks.2.norm1.bias\n",
      "decoder.blocks.2.attn.q_bias\n",
      "decoder.blocks.2.attn.v_bias\n",
      "decoder.blocks.2.attn.qkv.weight\n",
      "decoder.blocks.2.attn.proj.weight\n",
      "decoder.blocks.2.attn.proj.bias\n",
      "decoder.blocks.2.norm2.weight\n",
      "decoder.blocks.2.norm2.bias\n",
      "decoder.blocks.2.mlp.fc1.weight\n",
      "decoder.blocks.2.mlp.fc1.bias\n",
      "decoder.blocks.2.mlp.fc2.weight\n",
      "decoder.blocks.2.mlp.fc2.bias\n",
      "decoder.blocks.3.norm1.weight\n",
      "decoder.blocks.3.norm1.bias\n",
      "decoder.blocks.3.attn.q_bias\n",
      "decoder.blocks.3.attn.v_bias\n",
      "decoder.blocks.3.attn.qkv.weight\n",
      "decoder.blocks.3.attn.proj.weight\n",
      "decoder.blocks.3.attn.proj.bias\n",
      "decoder.blocks.3.norm2.weight\n",
      "decoder.blocks.3.norm2.bias\n",
      "decoder.blocks.3.mlp.fc1.weight\n",
      "decoder.blocks.3.mlp.fc1.bias\n",
      "decoder.blocks.3.mlp.fc2.weight\n",
      "decoder.blocks.3.mlp.fc2.bias\n",
      "decoder.norm.weight\n",
      "decoder.norm.bias\n",
      "decoder.head.weight\n",
      "decoder.head.bias\n",
      "encoder_to_decoder.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')\n",
    "\n",
    "for k, v  in state['model'].items():\n",
    "#     if 'encoder' in k:\n",
    "#         print(k.strip('encoder.'), v.shape)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############use_abs_pos: False\n",
      "############use_sincos_pos: True\n",
      "############use_rel_pos_bias: False\n",
      "##############patch here!!!\n",
      "##############patch here!!!\n",
      "##############self.pos_embed: Parameter containing:\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "from vitpytorch import VisionTransformerDet\n",
    "\n",
    "tmodel = VisionTransformerDet(img_size=[672, 1092], \n",
    "                     patch_size=16, \n",
    "                     embed_dim=768, \n",
    "                     depth=12, \n",
    "                     num_heads=12, \n",
    "                     init_values=0.1, \n",
    "                     mlp_ratio=4., \n",
    "                     drop_path_rate=0.2, \n",
    "                     drop_rate=0,\n",
    "                     use_abs_pos_emb=False, \n",
    "                     use_sincos_pos_emb=True, \n",
    "                     use_rel_pos_bias=False, \n",
    "                     use_checkpoint=False, \n",
    "                     out_indices=(3, 5, 7, 11),  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############patch here!!!\n"
     ]
    }
   ],
   "source": [
    "from vitpaddle import VisionTransformer\n",
    "\n",
    "pmodel = VisionTransformer(img_size=[672, 1092], \n",
    "                     patch_size=16, \n",
    "                     embed_dim=768, \n",
    "                     depth=12, \n",
    "                     num_heads=12, \n",
    "                     init_values=0.1, \n",
    "                     mlp_ratio=4., \n",
    "                     drop_path_rate=0.2, \n",
    "                     drop_rate=0,\n",
    "                     use_abs_pos_emb=False, \n",
    "                     # use_sincos_pos_emb=True, \n",
    "                     use_rel_pos_bias=False, \n",
    "                     use_checkpoint=False, \n",
    "                     epsilon=1e-6,\n",
    "                     out_indices=[3, 5, 7, 11],  )\n",
    "\n",
    "pmodel = model.backbone\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================pos_embed static ================\n",
      "pos_embed torch.Size([1, 2857, 768])\n"
     ]
    }
   ],
   "source": [
    "pmodel.eval()\n",
    "tmodel.eval()\n",
    "\n",
    "state = tmodel.state_dict().items()\n",
    "_state = {}\n",
    "\n",
    "for n, p in tmodel.state_dict().items():\n",
    "    if n == 'pos_embed':\n",
    "        print(n, p.shape)\n",
    "        \n",
    "    _p = p.cpu().data.numpy()\n",
    "    if len(_p.shape) == 2:\n",
    "        _p = _p.T\n",
    "    \n",
    "    if 'running_mean' in n:\n",
    "        n = n.replace('running_mean', '_mean')\n",
    "        \n",
    "    elif 'running_var' in n :\n",
    "        n = n.replace('running_var', '_variance')\n",
    "        \n",
    "    _state[n] = _p\n",
    "\n",
    "pmodel.set_state_dict(_state)\n",
    "\n",
    "\n",
    "paddle.save(_state, '../params/init.params')\n",
    "\n",
    "# for (tn, tv), (pn, pv) in zip(tmodel.state_dict().items(), pmodel.state_dict().items()):\n",
    "#     print(tn, tv.shape, pn, pv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(1, 3, 80, 80).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 768, 2, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[[[ 0.32955772,  1.31964457],\n",
      "          [ 1.19828069,  1.73772573]],\n",
      "\n",
      "         [[-0.83118159,  0.07101721],\n",
      "          [-0.06288959,  0.52549785]],\n",
      "\n",
      "         [[-0.73950201, -0.09849624],\n",
      "          [-0.24663055, -0.73018181]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.13671589,  0.89969426],\n",
      "          [ 0.94779062,  1.06741869]],\n",
      "\n",
      "         [[ 1.12805223,  1.15040290],\n",
      "          [ 1.29754519,  1.15821564]],\n",
      "\n",
      "         [[ 1.10358131,  1.07364833],\n",
      "          [ 1.11956239,  1.34705830]]]])\n"
     ]
    }
   ],
   "source": [
    "outputs = pmodel(paddle.to_tensor(data.copy()))\n",
    "print(outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 768, 20, 20] 7.662895950488746e-05 23.540424346923828\n",
      "[1, 768, 10, 10] -0.003116317791864276 -239.33316040039062\n",
      "[1, 768, 5, 5] 0.39099469780921936 7507.09765625\n",
      "[1, 768, 2, 2] 0.7190820574760437 2209.02001953125\n"
     ]
    }
   ],
   "source": [
    "for out in outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 0.3296,  1.3196],\n",
      "          [ 1.1983,  1.7377]],\n",
      "\n",
      "         [[-0.8312,  0.0710],\n",
      "          [-0.0629,  0.5255]],\n",
      "\n",
      "         [[-0.7395, -0.0985],\n",
      "          [-0.2466, -0.7302]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.1367,  0.8997],\n",
      "          [ 0.9478,  1.0674]],\n",
      "\n",
      "         [[ 1.1281,  1.1504],\n",
      "          [ 1.2975,  1.1582]],\n",
      "\n",
      "         [[ 1.1036,  1.0736],\n",
      "          [ 1.1196,  1.3471]]]], device='cuda:0',\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tmodel = tmodel.cuda()\n",
    "outputs = tmodel(torch.tensor(data.copy()).cuda())\n",
    "print(outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 20, 20]) 7.662902498850599e-05 23.540435791015625\n",
      "torch.Size([1, 768, 10, 10]) -0.0031163173262029886 -239.33316040039062\n",
      "torch.Size([1, 768, 5, 5]) 0.390994668006897 7507.09765625\n",
      "torch.Size([1, 768, 2, 2]) 0.7190820574760437 2209.02001953125\n"
     ]
    }
   ],
   "source": [
    "for out in outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
