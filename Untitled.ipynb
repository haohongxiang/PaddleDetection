{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly\n"
     ]
    }
   ],
   "source": [
    "import paddle\n",
    "import torch\n",
    "from ppdet.core.workspace import load_config, create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config('./configs/faster_rcnn/vit_base_16_faster_rcnn.yml')\n",
    "model = create(cfg.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')['model']\n",
    "\n",
    "state = {k.strip('encoder.'): v for k, v in state.items() if 'encoder' in k}\n",
    "\n",
    "_state = {}\n",
    "for n, p in model.backbone.state_dict().items():\n",
    "    if n in state:\n",
    "        if len(p.shape) == 2:\n",
    "            _state[n] = state[n].data.numpy().T\n",
    "        else:\n",
    "            _state[n] = state[n].data.numpy()\n",
    "\n",
    "            \n",
    "model.backbone.set_state_dict(_state)\n",
    "\n",
    "paddle.save(_state, '../params/pretrain_mae_vit_base_mask_0.75_400e.params')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask_token\n",
      "encoder.patch_embed.proj.weight\n",
      "encoder.patch_embed.proj.bias\n",
      "encoder.blocks.0.norm1.weight\n",
      "encoder.blocks.0.norm1.bias\n",
      "encoder.blocks.0.attn.q_bias\n",
      "encoder.blocks.0.attn.v_bias\n",
      "encoder.blocks.0.attn.qkv.weight\n",
      "encoder.blocks.0.attn.proj.weight\n",
      "encoder.blocks.0.attn.proj.bias\n",
      "encoder.blocks.0.norm2.weight\n",
      "encoder.blocks.0.norm2.bias\n",
      "encoder.blocks.0.mlp.fc1.weight\n",
      "encoder.blocks.0.mlp.fc1.bias\n",
      "encoder.blocks.0.mlp.fc2.weight\n",
      "encoder.blocks.0.mlp.fc2.bias\n",
      "encoder.blocks.1.norm1.weight\n",
      "encoder.blocks.1.norm1.bias\n",
      "encoder.blocks.1.attn.q_bias\n",
      "encoder.blocks.1.attn.v_bias\n",
      "encoder.blocks.1.attn.qkv.weight\n",
      "encoder.blocks.1.attn.proj.weight\n",
      "encoder.blocks.1.attn.proj.bias\n",
      "encoder.blocks.1.norm2.weight\n",
      "encoder.blocks.1.norm2.bias\n",
      "encoder.blocks.1.mlp.fc1.weight\n",
      "encoder.blocks.1.mlp.fc1.bias\n",
      "encoder.blocks.1.mlp.fc2.weight\n",
      "encoder.blocks.1.mlp.fc2.bias\n",
      "encoder.blocks.2.norm1.weight\n",
      "encoder.blocks.2.norm1.bias\n",
      "encoder.blocks.2.attn.q_bias\n",
      "encoder.blocks.2.attn.v_bias\n",
      "encoder.blocks.2.attn.qkv.weight\n",
      "encoder.blocks.2.attn.proj.weight\n",
      "encoder.blocks.2.attn.proj.bias\n",
      "encoder.blocks.2.norm2.weight\n",
      "encoder.blocks.2.norm2.bias\n",
      "encoder.blocks.2.mlp.fc1.weight\n",
      "encoder.blocks.2.mlp.fc1.bias\n",
      "encoder.blocks.2.mlp.fc2.weight\n",
      "encoder.blocks.2.mlp.fc2.bias\n",
      "encoder.blocks.3.norm1.weight\n",
      "encoder.blocks.3.norm1.bias\n",
      "encoder.blocks.3.attn.q_bias\n",
      "encoder.blocks.3.attn.v_bias\n",
      "encoder.blocks.3.attn.qkv.weight\n",
      "encoder.blocks.3.attn.proj.weight\n",
      "encoder.blocks.3.attn.proj.bias\n",
      "encoder.blocks.3.norm2.weight\n",
      "encoder.blocks.3.norm2.bias\n",
      "encoder.blocks.3.mlp.fc1.weight\n",
      "encoder.blocks.3.mlp.fc1.bias\n",
      "encoder.blocks.3.mlp.fc2.weight\n",
      "encoder.blocks.3.mlp.fc2.bias\n",
      "encoder.blocks.4.norm1.weight\n",
      "encoder.blocks.4.norm1.bias\n",
      "encoder.blocks.4.attn.q_bias\n",
      "encoder.blocks.4.attn.v_bias\n",
      "encoder.blocks.4.attn.qkv.weight\n",
      "encoder.blocks.4.attn.proj.weight\n",
      "encoder.blocks.4.attn.proj.bias\n",
      "encoder.blocks.4.norm2.weight\n",
      "encoder.blocks.4.norm2.bias\n",
      "encoder.blocks.4.mlp.fc1.weight\n",
      "encoder.blocks.4.mlp.fc1.bias\n",
      "encoder.blocks.4.mlp.fc2.weight\n",
      "encoder.blocks.4.mlp.fc2.bias\n",
      "encoder.blocks.5.norm1.weight\n",
      "encoder.blocks.5.norm1.bias\n",
      "encoder.blocks.5.attn.q_bias\n",
      "encoder.blocks.5.attn.v_bias\n",
      "encoder.blocks.5.attn.qkv.weight\n",
      "encoder.blocks.5.attn.proj.weight\n",
      "encoder.blocks.5.attn.proj.bias\n",
      "encoder.blocks.5.norm2.weight\n",
      "encoder.blocks.5.norm2.bias\n",
      "encoder.blocks.5.mlp.fc1.weight\n",
      "encoder.blocks.5.mlp.fc1.bias\n",
      "encoder.blocks.5.mlp.fc2.weight\n",
      "encoder.blocks.5.mlp.fc2.bias\n",
      "encoder.blocks.6.norm1.weight\n",
      "encoder.blocks.6.norm1.bias\n",
      "encoder.blocks.6.attn.q_bias\n",
      "encoder.blocks.6.attn.v_bias\n",
      "encoder.blocks.6.attn.qkv.weight\n",
      "encoder.blocks.6.attn.proj.weight\n",
      "encoder.blocks.6.attn.proj.bias\n",
      "encoder.blocks.6.norm2.weight\n",
      "encoder.blocks.6.norm2.bias\n",
      "encoder.blocks.6.mlp.fc1.weight\n",
      "encoder.blocks.6.mlp.fc1.bias\n",
      "encoder.blocks.6.mlp.fc2.weight\n",
      "encoder.blocks.6.mlp.fc2.bias\n",
      "encoder.blocks.7.norm1.weight\n",
      "encoder.blocks.7.norm1.bias\n",
      "encoder.blocks.7.attn.q_bias\n",
      "encoder.blocks.7.attn.v_bias\n",
      "encoder.blocks.7.attn.qkv.weight\n",
      "encoder.blocks.7.attn.proj.weight\n",
      "encoder.blocks.7.attn.proj.bias\n",
      "encoder.blocks.7.norm2.weight\n",
      "encoder.blocks.7.norm2.bias\n",
      "encoder.blocks.7.mlp.fc1.weight\n",
      "encoder.blocks.7.mlp.fc1.bias\n",
      "encoder.blocks.7.mlp.fc2.weight\n",
      "encoder.blocks.7.mlp.fc2.bias\n",
      "encoder.blocks.8.norm1.weight\n",
      "encoder.blocks.8.norm1.bias\n",
      "encoder.blocks.8.attn.q_bias\n",
      "encoder.blocks.8.attn.v_bias\n",
      "encoder.blocks.8.attn.qkv.weight\n",
      "encoder.blocks.8.attn.proj.weight\n",
      "encoder.blocks.8.attn.proj.bias\n",
      "encoder.blocks.8.norm2.weight\n",
      "encoder.blocks.8.norm2.bias\n",
      "encoder.blocks.8.mlp.fc1.weight\n",
      "encoder.blocks.8.mlp.fc1.bias\n",
      "encoder.blocks.8.mlp.fc2.weight\n",
      "encoder.blocks.8.mlp.fc2.bias\n",
      "encoder.blocks.9.norm1.weight\n",
      "encoder.blocks.9.norm1.bias\n",
      "encoder.blocks.9.attn.q_bias\n",
      "encoder.blocks.9.attn.v_bias\n",
      "encoder.blocks.9.attn.qkv.weight\n",
      "encoder.blocks.9.attn.proj.weight\n",
      "encoder.blocks.9.attn.proj.bias\n",
      "encoder.blocks.9.norm2.weight\n",
      "encoder.blocks.9.norm2.bias\n",
      "encoder.blocks.9.mlp.fc1.weight\n",
      "encoder.blocks.9.mlp.fc1.bias\n",
      "encoder.blocks.9.mlp.fc2.weight\n",
      "encoder.blocks.9.mlp.fc2.bias\n",
      "encoder.blocks.10.norm1.weight\n",
      "encoder.blocks.10.norm1.bias\n",
      "encoder.blocks.10.attn.q_bias\n",
      "encoder.blocks.10.attn.v_bias\n",
      "encoder.blocks.10.attn.qkv.weight\n",
      "encoder.blocks.10.attn.proj.weight\n",
      "encoder.blocks.10.attn.proj.bias\n",
      "encoder.blocks.10.norm2.weight\n",
      "encoder.blocks.10.norm2.bias\n",
      "encoder.blocks.10.mlp.fc1.weight\n",
      "encoder.blocks.10.mlp.fc1.bias\n",
      "encoder.blocks.10.mlp.fc2.weight\n",
      "encoder.blocks.10.mlp.fc2.bias\n",
      "encoder.blocks.11.norm1.weight\n",
      "encoder.blocks.11.norm1.bias\n",
      "encoder.blocks.11.attn.q_bias\n",
      "encoder.blocks.11.attn.v_bias\n",
      "encoder.blocks.11.attn.qkv.weight\n",
      "encoder.blocks.11.attn.proj.weight\n",
      "encoder.blocks.11.attn.proj.bias\n",
      "encoder.blocks.11.norm2.weight\n",
      "encoder.blocks.11.norm2.bias\n",
      "encoder.blocks.11.mlp.fc1.weight\n",
      "encoder.blocks.11.mlp.fc1.bias\n",
      "encoder.blocks.11.mlp.fc2.weight\n",
      "encoder.blocks.11.mlp.fc2.bias\n",
      "encoder.norm.weight\n",
      "encoder.norm.bias\n",
      "decoder.blocks.0.norm1.weight\n",
      "decoder.blocks.0.norm1.bias\n",
      "decoder.blocks.0.attn.q_bias\n",
      "decoder.blocks.0.attn.v_bias\n",
      "decoder.blocks.0.attn.qkv.weight\n",
      "decoder.blocks.0.attn.proj.weight\n",
      "decoder.blocks.0.attn.proj.bias\n",
      "decoder.blocks.0.norm2.weight\n",
      "decoder.blocks.0.norm2.bias\n",
      "decoder.blocks.0.mlp.fc1.weight\n",
      "decoder.blocks.0.mlp.fc1.bias\n",
      "decoder.blocks.0.mlp.fc2.weight\n",
      "decoder.blocks.0.mlp.fc2.bias\n",
      "decoder.blocks.1.norm1.weight\n",
      "decoder.blocks.1.norm1.bias\n",
      "decoder.blocks.1.attn.q_bias\n",
      "decoder.blocks.1.attn.v_bias\n",
      "decoder.blocks.1.attn.qkv.weight\n",
      "decoder.blocks.1.attn.proj.weight\n",
      "decoder.blocks.1.attn.proj.bias\n",
      "decoder.blocks.1.norm2.weight\n",
      "decoder.blocks.1.norm2.bias\n",
      "decoder.blocks.1.mlp.fc1.weight\n",
      "decoder.blocks.1.mlp.fc1.bias\n",
      "decoder.blocks.1.mlp.fc2.weight\n",
      "decoder.blocks.1.mlp.fc2.bias\n",
      "decoder.blocks.2.norm1.weight\n",
      "decoder.blocks.2.norm1.bias\n",
      "decoder.blocks.2.attn.q_bias\n",
      "decoder.blocks.2.attn.v_bias\n",
      "decoder.blocks.2.attn.qkv.weight\n",
      "decoder.blocks.2.attn.proj.weight\n",
      "decoder.blocks.2.attn.proj.bias\n",
      "decoder.blocks.2.norm2.weight\n",
      "decoder.blocks.2.norm2.bias\n",
      "decoder.blocks.2.mlp.fc1.weight\n",
      "decoder.blocks.2.mlp.fc1.bias\n",
      "decoder.blocks.2.mlp.fc2.weight\n",
      "decoder.blocks.2.mlp.fc2.bias\n",
      "decoder.blocks.3.norm1.weight\n",
      "decoder.blocks.3.norm1.bias\n",
      "decoder.blocks.3.attn.q_bias\n",
      "decoder.blocks.3.attn.v_bias\n",
      "decoder.blocks.3.attn.qkv.weight\n",
      "decoder.blocks.3.attn.proj.weight\n",
      "decoder.blocks.3.attn.proj.bias\n",
      "decoder.blocks.3.norm2.weight\n",
      "decoder.blocks.3.norm2.bias\n",
      "decoder.blocks.3.mlp.fc1.weight\n",
      "decoder.blocks.3.mlp.fc1.bias\n",
      "decoder.blocks.3.mlp.fc2.weight\n",
      "decoder.blocks.3.mlp.fc2.bias\n",
      "decoder.norm.weight\n",
      "decoder.norm.bias\n",
      "decoder.head.weight\n",
      "decoder.head.bias\n",
      "encoder_to_decoder.weight\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')\n",
    "\n",
    "for k, v  in state['model'].items():\n",
    "#     if 'encoder' in k:\n",
    "#         print(k.strip('encoder.'), v.shape)\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############use_abs_pos: False\n",
      "############use_sincos_pos: True\n",
      "############use_rel_pos_bias: False\n",
      "##############patch here!!!\n",
      "##############patch here!!!\n",
      "##############self.pos_embed: Parameter containing:\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    }
   ],
   "source": [
    "from vitpytorch import VisionTransformerDet\n",
    "\n",
    "tmodel = VisionTransformerDet(img_size=[672, 1092], \n",
    "                     patch_size=16, \n",
    "                     embed_dim=768, \n",
    "                     depth=12, \n",
    "                     num_heads=12, \n",
    "                     init_values=0.1, \n",
    "                     mlp_ratio=4., \n",
    "                     drop_path_rate=0.2, \n",
    "                     drop_rate=0,\n",
    "                     use_abs_pos_emb=False, \n",
    "                     use_sincos_pos_emb=True, \n",
    "                     use_rel_pos_bias=False, \n",
    "                     use_checkpoint=False, \n",
    "                     out_indices=(3, 5, 7, 11),  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############patch here!!!\n"
     ]
    }
   ],
   "source": [
    "from vitpaddle import VisionTransformer\n",
    "\n",
    "pmodel = VisionTransformer(img_size=[672, 1092], \n",
    "                     patch_size=16, \n",
    "                     embed_dim=768, \n",
    "                     depth=12, \n",
    "                     num_heads=12, \n",
    "                     init_values=0.1, \n",
    "                     mlp_ratio=4., \n",
    "                     drop_path_rate=0.2, \n",
    "                     drop_rate=0,\n",
    "                     use_abs_pos_emb=False, \n",
    "                     # use_sincos_pos_emb=True, \n",
    "                     use_rel_pos_bias=False, \n",
    "                     use_checkpoint=False, \n",
    "                     epsilon=1e-6,\n",
    "                     out_indices=[3, 5, 7, 11],  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================pos_embed static ================\n",
      "pos_embed torch.Size([1, 2857, 768])\n"
     ]
    }
   ],
   "source": [
    "pmodel.eval()\n",
    "tmodel.eval()\n",
    "\n",
    "state = tmodel.state_dict().items()\n",
    "_state = {}\n",
    "\n",
    "for n, p in tmodel.state_dict().items():\n",
    "    if n == 'pos_embed':\n",
    "        print(n, p.shape)\n",
    "        \n",
    "    _p = p.cpu().data.numpy()\n",
    "    if len(_p.shape) == 2:\n",
    "        _p = _p.T\n",
    "    \n",
    "    if 'running_mean' in n:\n",
    "        n = n.replace('running_mean', '_mean')\n",
    "        \n",
    "    elif 'running_var' in n :\n",
    "        n = n.replace('running_var', '_variance')\n",
    "        \n",
    "    _state[n] = _p\n",
    "\n",
    "pmodel.set_state_dict(_state)\n",
    "\n",
    "# for (tn, tv), (pn, pv) in zip(tmodel.state_dict().items(), pmodel.state_dict().items()):\n",
    "#     print(tn, tv.shape, pn, pv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(1, 3, 80, 80).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[1, 768, 2, 2], dtype=float32, place=CUDAPlace(0), stop_gradient=False,\n",
      "       [[[[-0.23001285,  0.62081087],\n",
      "          [ 0.73486680,  1.13512826]],\n",
      "\n",
      "         [[-0.82462025,  0.19726911],\n",
      "          [-0.27753335,  0.26463434]],\n",
      "\n",
      "         [[-1.04407465, -0.34687108],\n",
      "          [-0.34966013, -0.65305161]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.26024091,  1.32804036],\n",
      "          [ 1.30783522,  1.31657505]],\n",
      "\n",
      "         [[ 1.02239203,  0.78604025],\n",
      "          [ 1.10516322,  0.98746365]],\n",
      "\n",
      "         [[ 0.68139929,  0.62857586],\n",
      "          [ 0.71083468,  0.66501385]]]])\n"
     ]
    }
   ],
   "source": [
    "outputs = pmodel(paddle.to_tensor(data.copy()))\n",
    "print(outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 768, 20, 20] 0.00036657991586253047 112.6133804321289\n",
      "[1, 768, 10, 10] -0.00539160193875432 -414.07501220703125\n",
      "[1, 768, 5, 5] 0.4045824408531189 7767.98193359375\n",
      "[1, 768, 2, 2] 0.7317390441894531 2247.902099609375\n"
     ]
    }
   ],
   "source": [
    "for out in outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[-0.2300,  0.6208],\n",
      "          [ 0.7349,  1.1351]],\n",
      "\n",
      "         [[-0.8246,  0.1973],\n",
      "          [-0.2775,  0.2646]],\n",
      "\n",
      "         [[-1.0441, -0.3469],\n",
      "          [-0.3497, -0.6531]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.2602,  1.3280],\n",
      "          [ 1.3078,  1.3166]],\n",
      "\n",
      "         [[ 1.0224,  0.7860],\n",
      "          [ 1.1052,  0.9875]],\n",
      "\n",
      "         [[ 0.6814,  0.6286],\n",
      "          [ 0.7108,  0.6650]]]], device='cuda:0',\n",
      "       grad_fn=<MaxPool2DWithIndicesBackward0>)\n"
     ]
    }
   ],
   "source": [
    "tmodel = tmodel.cuda()\n",
    "outputs = tmodel(torch.tensor(data.copy()).cuda())\n",
    "print(outputs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 20, 20]) 0.0003665799449663609 112.61335754394531\n",
      "torch.Size([1, 768, 10, 10]) -0.0053916024044156075 -414.0750427246094\n",
      "torch.Size([1, 768, 5, 5]) 0.4045824408531189 7767.982421875\n",
      "torch.Size([1, 768, 2, 2]) 0.7317390441894531 2247.90234375\n"
     ]
    }
   ],
   "source": [
    "for out in outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
