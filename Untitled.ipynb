{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import paddle\n",
    "\n",
    "import torch\n",
    "from ppdet.core.workspace import load_config, create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############patch here!!!\n"
     ]
    }
   ],
   "source": [
    "cfg = load_config('./configs/vitdet/cascade_rcnn_vit_base_16_hrfpn_coco.yml')\n",
    "model = create(cfg.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')['model']\n",
    "\n",
    "# state = {k.strip('encoder.'): v for k, v in state.items() if 'encoder' in k}\n",
    "\n",
    "# _state = {}\n",
    "# for n, p in model.backbone.state_dict().items():\n",
    "#     if n in state:\n",
    "#         if len(p.shape) == 2:\n",
    "#             _state[n] = state[n].data.numpy().T\n",
    "#         else:\n",
    "#             _state[n] = state[n].data.numpy()\n",
    "\n",
    "            \n",
    "# model.backbone.set_state_dict(_state)\n",
    "\n",
    "# paddle.save(_state, '../params/pretrain_mae_vit_base_mask_0.75_400e.params')\n",
    "\n",
    "# import torch\n",
    "# state = torch.load('../params/pretrain_mae_vit_base_mask_0.75_400e.pth', map_location='cpu')\n",
    "\n",
    "# for k, v  in state['model'].items():\n",
    "# #     if 'encoder' in k:\n",
    "# #         print(k.strip('encoder.'), v.shape)\n",
    "#     # print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backbone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############use_abs_pos: False\n",
      "############use_sincos_pos: True\n",
      "############use_rel_pos_bias: False\n",
      "##############patch here!!!\n",
      "##############patch here!!!\n",
      "##############self.pos_embed: Parameter containing:\n",
      "tensor([[[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         ...,\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000],\n",
      "         [-0.8555,  0.8573, -0.9248,  ...,  1.0000,  1.0000,  1.0000]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['pos_embed', 'fpn1.0.weight', 'fpn1.0.bias', 'fpn1.1.weight', 'fpn1.1.bias', 'fpn1.1.running_mean', 'fpn1.1.running_var', 'fpn1.3.weight', 'fpn1.3.bias', 'fpn2.0.weight', 'fpn2.0.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vitpytorch import VisionTransformerDet\n",
    "\n",
    "tvit = VisionTransformerDet(img_size=[672, 1092], \n",
    "                     patch_size=16, \n",
    "                     embed_dim=768, \n",
    "                     depth=12, \n",
    "                     num_heads=12, \n",
    "                     init_values=0.1, \n",
    "                     mlp_ratio=4., \n",
    "                     drop_path_rate=0.2, \n",
    "                     drop_rate=0,\n",
    "                     use_abs_pos_emb=False, \n",
    "                     use_sincos_pos_emb=True, \n",
    "                     use_rel_pos_bias=False, \n",
    "                     use_checkpoint=False, \n",
    "                     out_indices=(3, 5, 7, 11),  )\n",
    "\n",
    "_t = torch.load('../params/cotr_base_v6.4_ep1600_4self_w2_mask0.5_dp0.1_checkpoint-1599_convert.pth', map_location='cpu')['model']\n",
    "\n",
    "_tt = {}\n",
    "\n",
    "for k, _ in tvit.state_dict().items():\n",
    "    if 'pos_embed' in k:\n",
    "        continue\n",
    "        \n",
    "    if 'encoder.' + k in _t:\n",
    "        # print(_t['encoder.' + k].shape)\n",
    "        \n",
    "        _tt[k] = _t['encoder.' + k]\n",
    "    \n",
    "tvit.load_state_dict(_tt, strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## paddle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from vitpaddle import VisionTransformer\n",
    "\n",
    "# pmodel = VisionTransformer(img_size=[672, 1092], \n",
    "#                      patch_size=16, \n",
    "#                      embed_dim=768, \n",
    "#                      depth=12, \n",
    "#                      num_heads=12, \n",
    "#                      init_values=0.1, \n",
    "#                      mlp_ratio=4., \n",
    "#                      drop_path_rate=0.2, \n",
    "#                      drop_rate=0,\n",
    "#                      use_abs_pos_emb=False, \n",
    "#                      # use_sincos_pos_emb=True, \n",
    "#                      use_rel_pos_bias=False, \n",
    "#                      use_checkpoint=False, \n",
    "#                      epsilon=1e-6,\n",
    "#                      out_indices=[3, 5, 7, 11],  )\n",
    "\n",
    "# pmodel = model.backbone\n",
    "\n",
    "pvit = model.backbone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================pos_embed static ================\n",
      "pos_embed torch.Size([1, 2857, 768])\n"
     ]
    }
   ],
   "source": [
    "pvit.eval()\n",
    "tvit.eval()\n",
    "\n",
    "# state = tvit.state_dict()\n",
    "_state = {}\n",
    "\n",
    "# keys_dict = {tk: pk for (tk, _), (pk, _) in zip(tvit.state_dict().items(), pvit.state_dict().items())}\n",
    "\n",
    "for n, p in tvit.state_dict().items():\n",
    "    if n == 'pos_embed':\n",
    "        print(n, p.shape)\n",
    "    \n",
    "    # _p = state[n] \n",
    "    _p = p.cpu().data.numpy()\n",
    "    \n",
    "    if len(_p.shape) == 2:\n",
    "        _p = _p.T\n",
    "    \n",
    "    if 'running_mean' in n:\n",
    "        n = n.replace('running_mean', '_mean')\n",
    "        \n",
    "    elif 'running_var' in n :\n",
    "        n = n.replace('running_var', '_variance')\n",
    "    \n",
    "    # _state[keys_dict[n]] = _p\n",
    "    \n",
    "    _state[n] = _p\n",
    "\n",
    "pvit.set_state_dict(_state)\n",
    "\n",
    "paddle.save(_state, '../params/init_pretrained.params')\n",
    "\n",
    "# for (tn, tv), (pn, pv) in zip(tvit.state_dict().items(), pvit.state_dict().items()):\n",
    "#     print(tn, tv.shape, pn, pv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.random.rand(1, 3, 160, 160).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 768, 40, 40] 0.0005334906745702028 655.55322265625\n",
      "[1, 768, 20, 20] 0.010502873919904232 3226.48291015625\n",
      "[1, 768, 10, 10] 0.3791421949863434 29118.119140625\n",
      "[1, 768, 5, 5] 0.6982982754707336 13407.3271484375\n"
     ]
    }
   ],
   "source": [
    "poutputs = pvit(paddle.to_tensor(data.copy()))\n",
    "# print(poutputs[-1])\n",
    "for out in poutputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 768, 40, 40]) 0.0005334906163625419 655.55322265625\n",
      "torch.Size([1, 768, 20, 20]) 0.010502874851226807 3226.483154296875\n",
      "torch.Size([1, 768, 10, 10]) 0.379142165184021 29118.1171875\n",
      "torch.Size([1, 768, 5, 5]) 0.6982982754707336 13407.326171875\n"
     ]
    }
   ],
   "source": [
    "tvit = tvit.cuda()\n",
    "toutputs = tvit(torch.tensor(data.copy()).cuda())\n",
    "# print(outputs[-1])\n",
    "\n",
    "for out in toutputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HRFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     neck=dict(\n",
    "#         type='HRFPN',\n",
    "#         in_channels=[768, 768, 768, 768],\n",
    "#         out_channels=256,\n",
    "#         num_outs=5),\n",
    "\n",
    "# from ppdet.modeling.necks.hrfpn import HRFPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cfg = load_config('./configs/cascade_rcnn/vit_base_16_hrfpn.yml')\n",
    "# neck = create(cfg.architecture).neck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from mmcv.cnn import ConvModule\n",
    "from mmcv.runner import BaseModule\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "\n",
    "class HRFPN(BaseModule):\n",
    "    '''https://github.com/open-mmlab/mmdetection/blob/master/mmdet/models/necks/hrfpn.py\n",
    "    '''\n",
    "    def __init__(self,\n",
    "                 in_channels,\n",
    "                 out_channels,\n",
    "                 num_outs=5,\n",
    "                 pooling_type='AVG',\n",
    "                 conv_cfg=None,\n",
    "                 norm_cfg=None,\n",
    "                 with_cp=False,\n",
    "                 stride=1,\n",
    "                 init_cfg=dict(type='Caffe2Xavier', layer='Conv2d')):\n",
    "        super(HRFPN, self).__init__(init_cfg)\n",
    "        assert isinstance(in_channels, list)\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.num_ins = len(in_channels)\n",
    "        self.num_outs = num_outs\n",
    "        self.with_cp = with_cp\n",
    "        self.conv_cfg = conv_cfg\n",
    "        self.norm_cfg = norm_cfg\n",
    "\n",
    "        self.reduction_conv = ConvModule(\n",
    "            sum(in_channels),\n",
    "            out_channels,\n",
    "            kernel_size=1,\n",
    "            conv_cfg=self.conv_cfg,\n",
    "            act_cfg=None)\n",
    "\n",
    "        self.fpn_convs = nn.ModuleList()\n",
    "        for i in range(self.num_outs):\n",
    "            self.fpn_convs.append(\n",
    "                ConvModule(\n",
    "                    out_channels,\n",
    "                    out_channels,\n",
    "                    kernel_size=3,\n",
    "                    padding=1,\n",
    "                    stride=stride,\n",
    "                    conv_cfg=self.conv_cfg,\n",
    "                    act_cfg=None))\n",
    "\n",
    "        if pooling_type == 'MAX':\n",
    "            self.pooling = F.max_pool2d\n",
    "        else:\n",
    "            self.pooling = F.avg_pool2d\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"Forward function.\"\"\"\n",
    "        assert len(inputs) == self.num_ins\n",
    "        outs = [inputs[0]]\n",
    "        \n",
    "        for i in range(1, self.num_ins):\n",
    "            outs.append(\n",
    "                F.interpolate(inputs[i], scale_factor=2**i, mode='bilinear'))\n",
    "            \n",
    "        out = torch.cat(outs, dim=1)\n",
    "        # print('out, ', out)\n",
    "\n",
    "        if out.requires_grad and self.with_cp:\n",
    "            out = checkpoint(self.reduction_conv, out)\n",
    "        else:\n",
    "            out = self.reduction_conv(out)\n",
    "            \n",
    "        # print('reduction_conv, ', out)\n",
    "\n",
    "        outs = [out]\n",
    "        for i in range(1, self.num_outs):\n",
    "            outs.append(self.pooling(out, kernel_size=2**i, stride=2**i))\n",
    "        outputs = []\n",
    "\n",
    "        for i in range(self.num_outs):\n",
    "            if outs[i].requires_grad and self.with_cp:\n",
    "                tmp_out = checkpoint(self.fpn_convs[i], outs[i])\n",
    "            else:\n",
    "                tmp_out = self.fpn_convs[i](outs[i])\n",
    "            outputs.append(tmp_out)\n",
    "        return tuple(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reduction_conv.conv.weight torch.Size([256, 3072, 1, 1])\n",
      "reduction_conv.conv.bias torch.Size([256])\n",
      "fpn_convs.0.conv.weight torch.Size([256, 256, 3, 3])\n",
      "fpn_convs.0.conv.bias torch.Size([256])\n",
      "fpn_convs.1.conv.weight torch.Size([256, 256, 3, 3])\n",
      "fpn_convs.1.conv.bias torch.Size([256])\n",
      "fpn_convs.2.conv.weight torch.Size([256, 256, 3, 3])\n",
      "fpn_convs.2.conv.bias torch.Size([256])\n",
      "fpn_convs.3.conv.weight torch.Size([256, 256, 3, 3])\n",
      "fpn_convs.3.conv.bias torch.Size([256])\n",
      "fpn_convs.4.conv.weight torch.Size([256, 256, 3, 3])\n",
      "fpn_convs.4.conv.bias torch.Size([256])\n",
      "-----\n",
      "reduction.weight [256, 3072, 1, 1]\n",
      "reduction.bias [256]\n",
      "fpn_conv_0.weight [256, 256, 3, 3]\n",
      "fpn_conv_0.bias [256]\n",
      "fpn_conv_1.weight [256, 256, 3, 3]\n",
      "fpn_conv_1.bias [256]\n",
      "fpn_conv_2.weight [256, 256, 3, 3]\n",
      "fpn_conv_2.bias [256]\n",
      "fpn_conv_3.weight [256, 256, 3, 3]\n",
      "fpn_conv_3.bias [256]\n",
      "fpn_conv_4.weight [256, 256, 3, 3]\n",
      "fpn_conv_4.bias [256]\n"
     ]
    }
   ],
   "source": [
    "tneck = HRFPN(in_channels=[768, 768, 768, 768], out_channels=256, num_outs=5).cuda()\n",
    "pneck = model.neck\n",
    "\n",
    "for n, p in tneck.state_dict().items():\n",
    "    print(n, p.shape)\n",
    "\n",
    "print('-----')\n",
    "for n, p in pneck.state_dict().items():\n",
    "    print(n, p.shape)\n",
    "    \n",
    "    \n",
    "# for (tn, tv), (pn, pv) in zip(tneck.state_dict().items(), pneck.state_dict().items()):\n",
    "#     print(tn, tv.shape, pn, pv.shape)\n",
    "\n",
    "\n",
    "pneck.eval()\n",
    "tneck.eval()\n",
    "\n",
    "\n",
    "_nect_state = {}\n",
    "keys_dict = {tk: pk for (tk, _), (pk, _) in zip(tneck.state_dict().items(), pneck.state_dict().items())}\n",
    "\n",
    "for n, p in tneck.state_dict().items():\n",
    "\n",
    "    _p = p.cpu().data.numpy()\n",
    "    \n",
    "    if len(_p.shape) == 2:\n",
    "        _p = _p.T\n",
    "    \n",
    "    if 'running_mean' in n:\n",
    "        n = n.replace('running_mean', '_mean')\n",
    "        \n",
    "    elif 'running_var' in n :\n",
    "        n = n.replace('running_var', '_variance')\n",
    "    \n",
    "    _nect_state[keys_dict[n]] = _p\n",
    "    \n",
    "    \n",
    "pneck.set_state_dict(_nect_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pneck.reduction.weight\n",
    "# tneck.reduction_conv.conv.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_neck_outputs = pneck(poutputs)\n",
    "t_neck_outputs = tneck(toutputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 256, 40, 40] 0.12531408667564392 51328.65625\n",
      "[1, 256, 20, 20] 0.21994656324386597 22522.53125\n",
      "[1, 256, 10, 10] 0.26829564571380615 6868.369140625\n",
      "[1, 256, 5, 5] 0.06000206619501114 384.01336669921875\n",
      "[1, 256, 2, 2] -0.1338818520307541 -137.0950164794922\n"
     ]
    }
   ],
   "source": [
    "for out in p_neck_outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 40, 40]) 0.12531402707099915 51328.62890625\n",
      "torch.Size([1, 256, 20, 20]) 0.21994659304618835 22522.53125\n",
      "torch.Size([1, 256, 10, 10]) 0.26829567551612854 6868.36962890625\n",
      "torch.Size([1, 256, 5, 5]) 0.060002077370882034 384.0133056640625\n",
      "torch.Size([1, 256, 2, 2]) -0.1338818073272705 -137.094970703125\n"
     ]
    }
   ],
   "source": [
    "for out in t_neck_outputs:\n",
    "    print(out.shape, out.mean().item(), out.sum().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RPNHead(\n",
       "  (anchor_generator): AnchorGenerator()\n",
       "  (rpn_feat): RPNFeat(\n",
       "    (rpn_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "  )\n",
       "  (rpn_rois_score): Conv2D(256, 3, kernel_size=[1, 1], data_format=NCHW)\n",
       "  (rpn_rois_delta): Conv2D(256, 12, kernel_size=[1, 1], data_format=NCHW)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.rpn_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CascadeHead(\n",
       "  (head): CascadeXConvNormHead(\n",
       "    (0): XConvNormHead(\n",
       "      (stage0_bbox_head_conv0): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage0_bbox_head_conv1): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage0_bbox_head_conv2): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage0_bbox_head_conv3): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "    )\n",
       "    (1): XConvNormHead(\n",
       "      (stage1_bbox_head_conv0): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage1_bbox_head_conv1): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage1_bbox_head_conv2): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage1_bbox_head_conv3): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "    )\n",
       "    (2): XConvNormHead(\n",
       "      (stage2_bbox_head_conv0): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage2_bbox_head_conv1): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage2_bbox_head_conv2): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (stage2_bbox_head_conv3): ConvNormLayer(\n",
       "        (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "        (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "      )\n",
       "      (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "    )\n",
       "  )\n",
       "  (bbox_score_stage0): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "  (bbox_delta_stage0): Linear(in_features=1024, out_features=4, dtype=float32)\n",
       "  (bbox_score_stage1): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "  (bbox_delta_stage1): Linear(in_features=1024, out_features=4, dtype=float32)\n",
       "  (bbox_score_stage2): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "  (bbox_delta_stage2): Linear(in_features=1024, out_features=4, dtype=float32)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.bbox_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_sincos_position_embedding(embed_dim=768,\n",
    "                                       temperature=10000.,\n",
    "                                       decode=False):\n",
    "    h, w = (16, 16)\n",
    "    grid_w = paddle.arange(w, dtype=paddle.float32)\n",
    "    grid_h = paddle.arange(h, dtype=paddle.float32)\n",
    "    grid_w, grid_h = paddle.meshgrid(grid_w, grid_h)\n",
    "    assert embed_dim % 4 == 0, 'Embed dimension must be divisible by 4 for 2D sin-cos position embedding'\n",
    "    pos_dim = embed_dim // 4\n",
    "    omega = paddle.arange(pos_dim, dtype=paddle.float32) / pos_dim\n",
    "    omega = 1. / (temperature ** omega)\n",
    "    print(omega)\n",
    "    \n",
    "    # out_w = paddle.einsum('m,d->md', [grid_w.flatten(), omega])\n",
    "    # out_h = paddle.einsum('m,d->md', [grid_h.flatten(), omega])\n",
    "    \n",
    "    out_w = grid_w.flatten()[..., None] @ omega[None]\n",
    "    out_h = grid_h.flatten()[..., None] @ omega[None]\n",
    "\n",
    "    pos_emb = paddle.concat([\n",
    "        paddle.sin(out_w), paddle.cos(out_w), paddle.sin(out_h),\n",
    "        paddle.cos(out_h) ], axis=1)[None, :, :]\n",
    "\n",
    "    pe_token = paddle.zeros([1, 1, embed_dim], dtype=paddle.float32)\n",
    "    pos_embed = paddle.concat([pe_token, pos_emb], axis=1)\n",
    "    # pos_embed.stop_gradient = True\n",
    "    \n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(shape=[4], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
      "       [1.        , 0.10000000, 0.01000000, 0.00100000])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor(shape=[1, 257, 16], dtype=float32, place=CUDAPlace(0), stop_gradient=True,\n",
       "       [[[0.        , 0.        , 0.        , ..., 0.        ,\n",
       "          0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 1.        ,\n",
       "          1.        , 1.        ],\n",
       "         [0.        , 0.        , 0.        , ..., 0.99500418,\n",
       "          0.99994999, 0.99999952],\n",
       "         ...,\n",
       "         [0.65028787, 0.99749500, 0.14943814, ..., 0.26749876,\n",
       "          0.99156189, 0.99991548],\n",
       "         [0.65028787, 0.99749500, 0.14943814, ..., 0.16996716,\n",
       "          0.99021602, 0.99990201],\n",
       "         [0.65028787, 0.99749500, 0.14943814, ..., 0.07073720,\n",
       "          0.98877108, 0.99988753]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_2d_sincos_position_embedding(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_2d_sincos_position_embedding_t(embed_dim=768, temperature=10000., decode=False):\n",
    "    h, w = (16, 16)\n",
    "    grid_w = torch.arange(w, dtype=torch.float32)\n",
    "    grid_h = torch.arange(h, dtype=torch.float32)\n",
    "    grid_w, grid_h = torch.meshgrid(grid_w, grid_h)\n",
    "    assert embed_dim % 4 == 0, 'Embed dimension must be divisible by 4 for 2D sin-cos position embedding'\n",
    "    pos_dim = embed_dim // 4\n",
    "    omega = torch.arange(pos_dim, dtype=torch.float32) / pos_dim\n",
    "    omega = 1. / (temperature ** omega)\n",
    "\n",
    "    out_w = torch.einsum('m,d->md', [grid_w.flatten(), omega])\n",
    "    # out_w = grid_w.flatten()[..., None] @ omega[None]\n",
    "    # print(out_w)\n",
    "    \n",
    "    out_h = torch.einsum('m,d->md', [grid_h.flatten(), omega])\n",
    "    pos_emb = torch.cat([torch.sin(out_w), torch.cos(out_w), torch.sin(out_h), torch.cos(out_h)], dim=1)[None, :, :]\n",
    "\n",
    "    pe_token = torch.zeros([1, 1, embed_dim], dtype=torch.float32)\n",
    "    pos_embed = torch.nn.Parameter(torch.cat([pe_token, pos_emb], dim=1))\n",
    "    pos_embed.requires_grad = False\n",
    "    return pos_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 1.0000, 1.0000, 1.0000],\n",
       "         [0.0000, 0.0000, 0.0000,  ..., 0.9950, 0.9999, 1.0000],\n",
       "         ...,\n",
       "         [0.6503, 0.9975, 0.1494,  ..., 0.2675, 0.9916, 0.9999],\n",
       "         [0.6503, 0.9975, 0.1494,  ..., 0.1700, 0.9902, 0.9999],\n",
       "         [0.6503, 0.9975, 0.1494,  ..., 0.0707, 0.9888, 0.9999]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "build_2d_sincos_position_embedding_t(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEMO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ppdet\n",
    "from ppdet.core.workspace import load_config, create, global_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = load_config('./configs/vitdet/cascade_rcnn_vit_base_16_hrfpn_coco.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############patch here!!!\n"
     ]
    }
   ],
   "source": [
    "m = create(cfg.architecture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CascadeRCNN(\n",
       "  (backbone): VisionTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv2D(3, 768, kernel_size=[16, 16], stride=[16, 16], data_format=NCHW)\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "    (blocks): LayerList(\n",
       "      (0): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (1): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (2): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (3): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (4): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (5): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (6): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (7): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (8): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (9): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (10): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "      (11): Block(\n",
       "        (norm1): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (attn): Attention(\n",
       "          (qkv): Linear(in_features=768, out_features=2304, dtype=float32)\n",
       "          (attn_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "          (proj): Linear(in_features=768, out_features=768, dtype=float32)\n",
       "          (proj_drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "        (drop_path): DropPath()\n",
       "        (norm2): LayerNorm(normalized_shape=[768], epsilon=1e-06)\n",
       "        (mlp): Mlp(\n",
       "          (fc1): Linear(in_features=768, out_features=3072, dtype=float32)\n",
       "          (act): GELU(approximate=False)\n",
       "          (fc2): Linear(in_features=3072, out_features=768, dtype=float32)\n",
       "          (drop): Dropout(p=0.0, axis=None, mode=upscale_in_train)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (norm): Identity()\n",
       "    (fpn1): Sequential(\n",
       "      (0): Conv2DTranspose(768, 768, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)\n",
       "      (1): SyncBatchNorm(num_features=768, momentum=0.1, epsilon=1e-05)\n",
       "      (2): GELU(approximate=False)\n",
       "      (3): Conv2DTranspose(768, 768, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)\n",
       "    )\n",
       "    (fpn2): Sequential(\n",
       "      (0): Conv2DTranspose(768, 768, kernel_size=[2, 2], stride=[2, 2], data_format=NCHW)\n",
       "    )\n",
       "    (fpn3): Identity()\n",
       "    (fpn4): MaxPool2D(kernel_size=2, stride=2, padding=0)\n",
       "  )\n",
       "  (rpn_head): RPNHead(\n",
       "    (anchor_generator): AnchorGenerator()\n",
       "    (rpn_feat): RPNFeat(\n",
       "      (rpn_conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "    )\n",
       "    (rpn_rois_score): Conv2D(256, 3, kernel_size=[1, 1], data_format=NCHW)\n",
       "    (rpn_rois_delta): Conv2D(256, 12, kernel_size=[1, 1], data_format=NCHW)\n",
       "  )\n",
       "  (bbox_head): CascadeHeadL(\n",
       "    (head): CascadeXConvNormHead(\n",
       "      (0): XConvNormHead(\n",
       "        (stage0_bbox_head_conv0): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage0_bbox_head_conv1): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage0_bbox_head_conv2): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage0_bbox_head_conv3): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "      )\n",
       "      (1): XConvNormHead(\n",
       "        (stage1_bbox_head_conv0): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage1_bbox_head_conv1): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage1_bbox_head_conv2): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage1_bbox_head_conv3): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "      )\n",
       "      (2): XConvNormHead(\n",
       "        (stage2_bbox_head_conv0): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage2_bbox_head_conv1): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage2_bbox_head_conv2): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (stage2_bbox_head_conv3): ConvNormLayer(\n",
       "          (conv): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "          (norm): BatchNorm2D(num_features=256, momentum=0.9, epsilon=1e-05)\n",
       "        )\n",
       "        (fc6): Linear(in_features=12544, out_features=1024, dtype=float32)\n",
       "      )\n",
       "    )\n",
       "    (bbox_score_stage0): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "    (bbox_delta_stage0): Linear(in_features=1024, out_features=320, dtype=float32)\n",
       "    (bbox_score_stage1): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "    (bbox_delta_stage1): Linear(in_features=1024, out_features=320, dtype=float32)\n",
       "    (bbox_score_stage2): Linear(in_features=1024, out_features=81, dtype=float32)\n",
       "    (bbox_delta_stage2): Linear(in_features=1024, out_features=320, dtype=float32)\n",
       "  )\n",
       "  (neck): HRFPN(\n",
       "    (reduction): Conv2D(3072, 256, kernel_size=[1, 1], data_format=NCHW)\n",
       "    (fpn_conv_0): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "    (fpn_conv_1): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "    (fpn_conv_2): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "    (fpn_conv_3): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "    (fpn_conv_4): Conv2D(256, 256, kernel_size=[3, 3], padding=1, data_format=NCHW)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
