  File "tools/train.py", line 27
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
  File "tools/train.py", line 297
    =======
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 15, in <module>
    from . import source
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/__init__.py", line 15, in <module>
    from . import coco
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/coco.py", line 132
    <<<<<<< HEAD
    ^
IndentationError: expected an indented block
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 15, in <module>
    from . import source
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/__init__.py", line 15, in <module>
    from . import coco
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/coco.py", line 17, in <module>
    from ppdet.core.workspace import register, serializable
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/core/workspace.py", line 152
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 15, in <module>
    from . import source
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/__init__.py", line 15, in <module>
    from . import coco
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/coco.py", line 18, in <module>
    from .dataset import DetDataset
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/dataset.py", line 118
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 15, in <module>
    from . import source
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/__init__.py", line 15, in <module>
    from . import coco
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/coco.py", line 18, in <module>
    from .dataset import DetDataset
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/dataset.py", line 24, in <module>
    from ppdet.utils.download import get_dataset_path
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/utils/download.py", line 28
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 19, in <module>
    from . import ops
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/ops.py", line 56
    <<<<<<< HEAD
    ^
IndentationError: expected an indented block
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 19, in <module>
    from . import mobilenet_v3
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/mobilenet_v3.py", line 26
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 19, in <module>
    from . import mobilenet_v3
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/mobilenet_v3.py", line 150
    =======
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 19, in <module>
    from . import mobilenet_v3
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/mobilenet_v3.py", line 61
    >>>>>>> 879c90b6d0420410973f5e22932417d174ef45a9
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 28, in <module>
    from . import cspdarknet
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/cspdarknet.py", line 3
    from __future__ import absolute_import
    ^
SyntaxError: from __future__ imports must occur at the beginning of the file
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 28, in <module>
    from . import cspdarknet
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/cspdarknet.py", line 10, in <module>
    from ..architectures.common import parse_model
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/architectures/__init__.py", line 16, in <module>
    from . import ttfnet
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/architectures/ttfnet.py", line 50
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 20, in <module>
    from . import backbones
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/__init__.py", line 28, in <module>
    from . import cspdarknet
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/backbones/cspdarknet.py", line 10, in <module>
    from ..architectures.common import parse_model
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/architectures/__init__.py", line 20, in <module>
    from . import jde
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/architectures/jde.py", line 20, in <module>
    from ppdet.modeling.mot.utils import scale_coords
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/mot/__init__.py", line 15, in <module>
    from . import matching
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/mot/matching/__init__.py", line 15, in <module>
    from . import jde_matching
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/mot/matching/jde_matching.py", line 18, in <module>
    import lap
ModuleNotFoundError: No module named 'lap'
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 23, in <module>
    from . import heads
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/heads/__init__.py", line 27, in <module>
    from . import centernet_head
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/heads/centernet_head.py", line 21, in <module>
    from ppdet.modeling.losses import CTFocalLoss
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/losses/__init__.py", line 16, in <module>
    from . import iou_aware_loss
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/losses/iou_aware_loss.py", line 21, in <module>
    from .iou_loss import IouLoss
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/losses/iou_loss.py", line 199
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 41, in <module>
    from ppdet.modeling import bbox_utils
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/__init__.py", line 23, in <module>
    from . import heads
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/heads/__init__.py", line 27, in <module>
    from . import centernet_head
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/heads/centernet_head.py", line 21, in <module>
    from ppdet.modeling.losses import CTFocalLoss
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/losses/__init__.py", line 19, in <module>
    from . import fcos_loss
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/modeling/losses/fcos_loss.py", line 80
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Traceback (most recent call last):
  File "tools/train.py", line 33, in <module>
    from ppdet.core.workspace import load_config, merge_config
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/__init__.py", line 15, in <module>
    from . import (core, data, engine, modeling, model_zoo, optimizer, metrics,
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/__init__.py", line 16, in <module>
    from . import transform
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/__init__.py", line 15, in <module>
    from . import operators
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/operators.py", line 42, in <module>
    from ..reader import Compose
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/reader.py", line 171
    <<<<<<< HEAD
     ^
SyntaxError: invalid syntax
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
Traceback (most recent call last):
  File "tools/train.py", line 139, in <module>
    main()
  File "tools/train.py", line 115, in main
    cfg = load_config(FLAGS.config)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/core/workspace.py", line 112, in load_config
    cfg = _load_config_with_base(file_path)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/core/workspace.py", line 92, in _load_config_with_base
    base_cfg = _load_config_with_base(base_yml)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/core/workspace.py", line 79, in _load_config_with_base
    file_cfg = yaml.load(f, Loader=yaml.Loader)
  File "/usr/local/lib/python3.7/dist-packages/yaml/__init__.py", line 114, in load
    return loader.get_single_data()
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 51, in get_single_data
    return self.construct_document(node)
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 60, in construct_document
    for dummy in generator:
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 408, in construct_yaml_seq
    data.extend(self.construct_sequence(node))
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 130, in construct_sequence
    for child in node.value]
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 130, in <listcomp>
    for child in node.value]
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 100, in construct_object
    data = constructor(self, node)
  File "/usr/local/lib/python3.7/dist-packages/yaml/constructor.py", line 429, in construct_undefined
    node.start_mark)
yaml.constructor.ConstructorError: could not determine a constructor for the tag '!OneCycle'
  in "configs/yolov5/_base_/optimizer.yml", line 6, column 7
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
I0809 03:45:28.656443  8754 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:47300 successful.
I0809 03:45:29.175804  8754 nccl_context.cc:74] init nccl context nranks: 4 local rank: 1 gpu id: 1 ring id: 0
W0809 03:45:30.171576  8754 device_context.cc:404] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0809 03:45:30.179325  8754 device_context.cc:422] device: 1, cuDNN Version: 8.1.
loading annotations into memory...
Done (t=3.82s)
creating index...
index created!
--------steps_per_epoch--------
97
Config dataset_dir ../../dataset/coco is not exits, dataset config is not valid
WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

Process Process-6:
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/process.py", line 297, in _bootstrap
    self.run()
  File "/usr/lib/python3.7/multiprocessing/process.py", line 99, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/worker.py", line 346, in _worker_loop
    six.reraise(*sys.exc_info())
  File "/usr/local/lib/python3.7/dist-packages/six.py", line 719, in reraise
    raise value
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/worker.py", line 341, in _worker_loop
    out_queue.put((idx, batch, structure))
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 87, in put
    self._start_thread()
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 170, in _start_thread
    self._thread.start()
  File "/usr/lib/python3.7/threading.py", line 852, in start
    _start_new_thread(self._bootstrap, ())
RuntimeError: can't start new thread
Traceback (most recent call last):
  File "tools/train.py", line 139, in <module>
    main()
  File "tools/train.py", line 135, in main
    run(FLAGS, cfg)
  File "tools/train.py", line 110, in run
    trainer.train(FLAGS.eval)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/engine/trainer.py", line 257, in train
    self._init_metrics(validate=validate)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/engine/trainer.py", line 166, in _init_metrics
    eval_dataset.check_or_download_dataset()
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/source/dataset.py", line 90, in check_or_download_dataset
    self.image_dir)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/utils/download.py", line 213, in get_dataset_path
    get_path(url, data_dir, md5sum, check_exist)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/utils/download.py", line 288, in get_path
    fullname = _download_dist(url, root_dir, md5sum)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/utils/download.py", line 413, in _download_dist
    time.sleep(0.5)
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/multiprocess_utils.py", line 138, in __handler__
    core._throw_error_if_process_failed()
SystemError: (Fatal) DataLoader process (pid 8884) exited unexpectedly with code 1. Error detailed are lost due to multiprocessing. Rerunning with:
  1. If run DataLoader by DataLoader.from_generator(...), run with DataLoader.from_generator(..., use_multiprocess=False) may give better error trace.
  2. If run DataLoader by DataLoader(dataset, ...), run with DataLoader(dataset, ..., num_workers=0) may give better error trace (at /paddle/paddle/fluid/imperative/data_loader.cc:156)

Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
I0809 03:49:33.563318 10319 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:24868 successful.
I0809 03:49:34.111037 10319 nccl_context.cc:74] init nccl context nranks: 4 local rank: 1 gpu id: 1 ring id: 0
W0809 03:49:35.270867 10319 device_context.cc:404] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0809 03:49:35.285432 10319 device_context.cc:422] device: 1, cuDNN Version: 8.1.
loading annotations into memory...
Done (t=3.60s)
creating index...
index created!
Shared memory size is less than 1G, disable shared_memory in DataLoader
--------steps_per_epoch--------
97
Config dataset_dir ../../dataset/coco is not exits, dataset config is not valid
  0%|          | 0/18883655 [00:00<?, ?KB/s]  0%|          | 7/18883655 [00:00<176:22:37, 29.74KB/s]  0%|          | 19/18883655 [00:00<137:11:45, 38.23KB/s]  0%|          | 34/18883655 [00:00<99:50:55, 52.53KB/s]   0%|          | 40/18883655 [00:01<227:38:10, 23.04KB/s]  0%|          | 61/18883655 [00:01<135:42:00, 38.65KB/s]  0%|          | 68/18883655 [00:01<144:43:26, 36.24KB/s]  0%|          | 76/18883655 [00:02<187:28:13, 27.98KB/s]  0%|          | 86/18883655 [00:02<168:13:01, 31.18KB/s]  0%|          | 91/18883655 [00:02<183:15:59, 28.62KB/s]  0%|          | 101/18883655 [00:03<163:32:03, 32.08KB/s]  0%|          | 111/18883655 [00:03<151:03:46, 34.72KB/s]  0%|          | 121/18883655 [00:03<142:55:15, 36.70KB/s]  0%|          | 131/18883655 [00:03<137:27:15, 38.16KB/s]  0%|          | 136/18883655 [00:04<204:02:41, 25.71KB/s]  0%|          | 150/18883655 [00:04<155:42:57, 33.69KB/s]  0%|          | 157/18883655 [00:04<161:09:43, 32.55KB/s]  0%|          | 163/18883655 [00:05<217:58:57, 24.06KB/s]  0%|          | 167/18883655 [00:05<234:36:44, 22.36KB/s]  0%|          | 177/18883655 [00:05<192:48:48, 27.20KB/s]  0%|          | 181/18883655 [00:06<270:54:11, 19.36KB/s]  0%|          | 191/18883655 [00:06<214:02:40, 24.51KB/s]  0%|          | 196/18883655 [00:06<278:20:02, 18.85KB/s]  0%|          | 199/18883655 [00:07<300:23:48, 17.46KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 202/18883655 [00:07<398:56:01, 13.15KB/s]  0%|          | 210/18883655 [00:07<299:11:41, 17.53KB/s]  0%|          | 214/18883655 [00:08<302:29:37, 17.34KB/s]  0%|          | 221/18883655 [00:08<257:51:19, 20.34KB/s]  0%|          | 228/18883655 [00:08<231:00:45, 22.71KB/s]  0%|          | 235/18883655 [00:08<214:03:44, 24.50KB/s]  0%|          | 242/18883655 [00:09<202:57:55, 25.84KB/s]  0%|          | 249/18883655 [00:09<195:33:32, 26.82KB/s]  0%|          | 256/18883655 [00:09<190:32:41, 27.53KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 266/18883655 [00:09<165:25:51, 31.71KB/s]  0%|          | 276/18883655 [00:10<151:14:53, 34.68KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 286/18883655 [00:10<142:33:39, 36.79KB/s]  0%|          | 293/18883655 [00:10<197:32:32, 26.55KB/s]  0%|          | 310/18883655 [00:11<139:48:52, 37.52KB/s]  0%|          | 318/18883655 [00:11<143:53:37, 36.45KB/s]  0%|          | 324/18883655 [00:11<199:55:28, 26.24KB/s]  0%|          | 333/18883655 [00:11<181:32:22, 28.89KB/s]  0%|          | 339/18883655 [00:12<187:46:16, 27.93KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 346/18883655 [00:12<185:25:35, 28.29KB/s]  0%|          | 353/18883655 [00:12<242:45:20, 21.61KB/s]  0%|          | 363/18883655 [00:13<200:06:15, 26.21KB/s]  0%|          | 367/18883655 [00:13<219:39:34, 23.88KB/s]  0%|          | 374/18883655 [00:13<207:30:24, 25.28KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 378/18883655 [00:14<282:32:58, 18.56KB/s]  0%|          | 388/18883655 [00:14<217:39:24, 24.10KB/s]  0%|          | 393/18883655 [00:14<225:14:33, 23.29KB/s]  0%|          | 396/18883655 [00:15<325:08:52, 16.13KB/s]  0%|          | 405/18883655 [00:15<248:39:10, 21.10KB/s]  0%|          | 410/18883655 [00:15<249:11:36, 21.05KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 417/18883655 [00:15<226:07:11, 23.20KB/s]  0%|          | 424/18883655 [00:16<211:06:13, 24.85KB/s]  0%|          | 427/18883655 [00:16<253:41:14, 20.68KB/s]  0%|          | 434/18883655 [00:16<219:25:01, 23.91KB/s]  0%|          | 438/18883655 [00:16<240:31:45, 21.81KB/s]  0%|          | 444/18883655 [00:17<306:39:57, 17.10KB/s]  0%|          | 449/18883655 [00:17<282:24:15, 18.57KB/s]  0%|          | 456/18883655 [00:17<245:29:27, 21.37KB/s]  0%|          | 459/18883655 [00:18<349:34:21, 15.00KB/s]  0%|          | 466/18883655 [00:18<285:46:09, 18.36KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 470/18883655 [00:18<292:20:08, 17.94KB/s]WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

  0%|          | 476/18883655 [00:18<264:31:02, 19.83KB/s]  0%|          | 482/18883655 [00:19<246:37:49, 21.27KB/s]  0%|          | 487/18883655 [00:19<247:50:04, 21.16KB/s]  0%|          | 493/18883655 [00:19<235:22:32, 22.28KB/s]  0%|          | 498/18883655 [00:19<239:41:10, 21.88KB/s]  0%|          | 505/18883655 [00:20<218:13:57, 24.04KB/s]  0%|          | 512/18883655 [00:20<205:02:36, 25.58KB/s]  0%|          | 522/18883655 [00:20<172:34:23, 30.39KB/s]  0%|          | 532/18883655 [00:20<155:13:49, 33.79KB/s]  0%|          | 536/18883655 [00:21<238:45:29, 21.97KB/s]  0%|          | 540/18883655 [00:21<251:59:43, 20.82KB/s]  0%|          | 547/18883655 [00:21<227:48:49, 23.02KB/s]  0%|          | 554/18883655 [00:22<212:11:11, 24.72KB/s]  0%|          | 557/18883655 [00:22<247:57:48, 21.15KB/s]  0%|          | 560/18883655 [00:22<278:16:37, 18.85KB/s]  0%|          | 570/18883655 [00:22<205:36:42, 25.51KB/s]  0%|          | 577/18883655 [00:22<197:08:09, 26.61KB/s]  0%|          | 584/18883655 [00:23<191:29:04, 27.39KB/s]  0%|          | 591/18883655 [00:23<187:42:02, 27.95KB/s]  0%|          | 595/18883655 [00:23<276:40:44, 18.96KB/s]  0%|          | 606/18883655 [00:24<204:42:50, 25.62KB/s]  0%|          | 609/18883655 [00:24<290:02:08, 18.08KB/s]  0%|          | 613/18883655 [00:25<363:49:06, 14.42KB/s]  0%|          | 623/18883655 [00:25<259:13:46, 20.23KB/s]  0%|          | 627/18883655 [00:25<270:08:24, 19.42KB/s]  0%|          | 634/18883655 [00:25<239:48:08, 21.87KB/s]  0%|          | 640/18883655 [00:26<291:34:18, 17.99KB/s]  0%|          | 649/18883655 [00:26<233:15:56, 22.49KB/s]  0%|          | 654/18883655 [00:26<237:23:04, 22.10KB/s]  0%|          | 661/18883655 [00:27<218:55:14, 23.96KB/s]  0%|          | 668/18883655 [00:27<206:31:10, 25.40KB/s]  0%|          | 675/18883655 [00:27<198:08:10, 26.47KB/s]  0%|          | 679/18883655 [00:28<406:03:52, 12.92KB/s]  0%|          | 693/18883655 [00:28<247:22:31, 21.20KB/s]  0%|          | 697/18883655 [00:28<258:40:49, 20.28KB/s]  0%|          | 700/18883655 [00:29<283:13:23, 18.52KB/s]  0%|          | 704/18883655 [00:29<290:08:07, 18.08KB/s]  0%|          | 708/18883655 [00:30<526:18:29,  9.97KB/s]  0%|          | 717/18883655 [00:31<470:41:56, 11.14KB/s]Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
MemoryError
  0%|          | 725/18883655 [00:31<358:05:14, 14.65KB/s]  0%|          | 729/18883655 [00:31<349:03:58, 15.03KB/s]  0%|          | 733/18883655 [00:31<341:05:15, 15.38KB/s]  0%|          | 735/18883655 [00:32<469:07:08, 11.18KB/s]  0%|          | 743/18883655 [00:32<331:00:03, 15.85KB/s]  0%|          | 747/18883655 [00:32<328:09:37, 15.98KB/s]  0%|          | 749/18883655 [00:33<459:38:00, 11.41KB/s]  0%|          | 756/18883655 [00:33<341:09:31, 15.37KB/s]  0%|          | 760/18883655 [00:33<334:08:00, 15.70KB/s]  0%|          | 763/18883655 [00:33<352:18:40, 14.89KB/s]  0%|          | 767/18883655 [00:34<341:04:39, 15.38KB/s]  0%|          | 771/18883655 [00:34<333:04:36, 15.75KB/s]  0%|          | 777/18883655 [00:34<285:14:42, 18.39KB/s]  0%|          | 779/18883655 [00:35<430:03:59, 12.20KB/s]fail to map batch transform [Gt2Yolov5Target_d0cbdb] with error: Unable to allocate 268. MiB for an array with shape (43, 3, 85, 80, 80) and data type float32 and stack:
Traceback (most recent call last):
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/reader.py", line 73, in __call__
    data = f(data)
  File "/home/codes/train_yolov5/PaddleDetection/ppdet/data/transform/batch_operators.py", line 324, in __call__
    dtype=np.float32)
numpy.core._exceptions._ArrayMemoryError: Unable to allocate 268. MiB for an array with shape (43, 3, 85, 80, 80) and data type float32

ERROR:root:DataLoader reader thread raised an exception!
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 411, in _thread_loop
    batch = self._get_data()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 525, in _get_data
    batch.reraise()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/worker.py", line 168, in reraise
    raise self.exc_type(msg)
TypeError: __init__() missing 1 required positional argument: 'dtype'

  0%|          | 785/18883655 [00:35<425:18:30, 12.33KB/s]  0%|          | 788/18883655 [00:35<423:45:56, 12.38KB/s]  0%|          | 792/18883655 [00:36<391:05:13, 13.41KB/s]  0%|          | 795/18883655 [00:36<397:37:22, 13.19KB/s]  0%|          | 798/18883655 [00:36<402:53:47, 13.02KB/s]  0%|          | 803/18883655 [00:36<345:15:13, 15.19KB/s]  0%|          | 807/18883655 [00:37<430:38:47, 12.18KB/s]Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
  0%|          | 814/18883655 [00:37<470:00:02, 11.16KB/s]  0%|          | 819/18883655 [00:38<403:10:29, 13.01KB/s]  0%|          | 821/18883655 [00:38<436:29:48, 12.02KB/s]  0%|          | 824/18883655 [00:38<432:05:38, 12.14KB/s]  0%|          | 830/18883655 [00:38<341:05:40, 15.38KB/s]  0%|          | 834/18883655 [00:39<421:18:35, 12.45KB/s]  0%|          | 841/18883655 [00:39<321:42:05, 16.30KB/s]  0%|          | 844/18883655 [00:39<341:07:10, 15.38KB/s]  0%|          | 848/18883655 [00:40<333:35:20, 15.72KB/s]  0%|          | 854/18883655 [00:40<287:14:33, 18.26KB/s]  0%|          | 859/18883655 [00:40<276:03:39, 19.00KB/s]  0%|          | 865/18883655 [00:40<252:59:14, 20.73KB/s]  0%|          | 870/18883655 [00:41<252:23:08, 20.78KB/s]  0%|          | 876/18883655 [00:41<237:58:49, 22.04KB/s]Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
  0%|          | 884/18883655 [00:41<206:30:26, 25.40KB/s]  0%|          | 893/18883655 [00:41<180:43:02, 29.02KB/s]  0%|          | 901/18883655 [00:42<172:53:38, 30.34KB/s]

--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::SignalHandle(char const*, int)
1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1628481032 (unix time) try "date -d @1628481032" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x280d) received by PID 10319 (TID 0x7fc556b5b740) from PID 10253 ***]

Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
I0809 03:51:11.876086 11857 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:49475 successful.
I0809 03:51:12.213522 11857 nccl_context.cc:74] init nccl context nranks: 4 local rank: 1 gpu id: 1 ring id: 0
W0809 03:51:13.223100 11857 device_context.cc:404] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0809 03:51:13.229938 11857 device_context.cc:422] device: 1, cuDNN Version: 8.1.
loading annotations into memory...
Done (t=3.72s)
creating index...
index created!
--------steps_per_epoch--------
97
Config dataset_dir ../../dataset/coco is not exits, dataset config is not valid
WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

ERROR:root:DataLoader reader thread raised an exception!
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 411, in _thread_loop
    batch = self._get_data()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 525, in _get_data
    batch.reraise()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/worker.py", line 168, in reraise
    raise self.exc_type(msg)
TypeError: __init__() missing 1 required positional argument: 'dtype'

Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
MemoryError
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB


--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::SignalHandle(char const*, int)
1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1628481133 (unix time) try "date -d @1628481133" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x2e0e) received by PID 11857 (TID 0x7fe9079e0740) from PID 11790 ***]

Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
Traceback (most recent call last):
  File "/usr/lib/python3.7/multiprocessing/queues.py", line 236, in _feed
    obj = _ForkingPickler.dumps(obj)
  File "/usr/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
OverflowError: cannot serialize a bytes object larger than 4 GiB
grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
I0809 03:59:08.695900 13847 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:45345 successful.
I0809 03:59:09.155773 13847 nccl_context.cc:74] init nccl context nranks: 4 local rank: 1 gpu id: 1 ring id: 0
W0809 03:59:10.368727 13847 device_context.cc:404] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0809 03:59:10.375355 13847 device_context.cc:422] device: 1, cuDNN Version: 8.1.
loading annotations into memory...
Done (t=3.71s)
creating index...
index created!
--------steps_per_epoch--------
97
Config dataset_dir ../../dataset/coco is not exits, dataset config is not valid
WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

grep: warning: GREP_OPTIONS is deprecated; please use an alias or script
/usr/local/lib/python3.7/dist-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. 
Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations
  if data.dtype == np.object:
Warning: import ppdet from source directory without installing, run 'python setup.py install' to install ppdet firstly
I0809 04:03:25.185659 14242 gen_comm_id_helper.cc:181] Server listening on: 127.0.0.1:57266 successful.
I0809 04:03:25.451054 14242 nccl_context.cc:74] init nccl context nranks: 4 local rank: 1 gpu id: 1 ring id: 0
W0809 04:03:26.497993 14242 device_context.cc:404] Please NOTE: device: 1, GPU Compute Capability: 7.0, Driver API Version: 11.2, Runtime API Version: 11.2
W0809 04:03:26.505012 14242 device_context.cc:422] device: 1, cuDNN Version: 8.1.
loading annotations into memory...
Done (t=4.11s)
creating index...
index created!
--------steps_per_epoch--------
97
Config dataset_dir ../../dataset/coco is not exits, dataset config is not valid
WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

ERROR:root:DataLoader reader thread raised an exception!
Exception in thread Thread-1:
Traceback (most recent call last):
  File "/usr/lib/python3.7/threading.py", line 926, in _bootstrap_inner
    self.run()
  File "/usr/lib/python3.7/threading.py", line 870, in run
    self._target(*self._args, **self._kwargs)
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 411, in _thread_loop
    batch = self._get_data()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/dataloader_iter.py", line 525, in _get_data
    batch.reraise()
  File "/usr/local/lib/python3.7/dist-packages/paddle/fluid/dataloader/worker.py", line 168, in reraise
    raise self.exc_type(msg)
TypeError: __init__() missing 1 required positional argument: 'dtype'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'

WARNING: Detect dataset only contains single fileds, return format changed since Paddle 2.1. In Paddle <= 2.0, DataLoader add a list surround output data(e.g. return [data]), and in Paddle >= 2.1, DataLoader return the single filed directly (e.g. return data). For example, in following code: 

import numpy as np
from paddle.io import DataLoader, Dataset

class RandomDataset(Dataset):
    def __getitem__(self, idx):
        data = np.random.random((2, 3)).astype('float32')

        return data

    def __len__(self):
        return 10

dataset = RandomDataset()
loader = DataLoader(dataset, batch_size=1)
data = next(loader())

In Paddle <= 2.0, data is in format '[Tensor(shape=(1, 2, 3), dtype=float32)]', and in Paddle >= 2.1, data is in format 'Tensor(shape=(1, 2, 3), dtype=float32)'



--------------------------------------
C++ Traceback (most recent call last):
--------------------------------------
0   paddle::framework::SignalHandle(char const*, int)
1   paddle::platform::GetCurrentTraceBackString[abi:cxx11]()

----------------------
Error Message Summary:
----------------------
FatalError: `Termination signal` is detected by the operating system.
  [TimeInfo: *** Aborted at 1628481837 (unix time) try "date -d @1628481837" if you are using GNU date ***]
  [SignalInfo: *** SIGTERM (@0x3760) received by PID 14242 (TID 0x7fe229314740) from PID 14176 ***]

